#!/usr/bin/env python3
"""
é«˜åº¦ãªåˆ†æã‚·ã‚¹ãƒ†ãƒ  - æŠ½è±¡åŒ–å­¦ç¿’æ©Ÿèƒ½ä»˜ã
å…·ä½“çš„ãªä¿®æ­£ã‹ã‚‰ä¸€èˆ¬çš„ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å­¦ç¿’ã—ã€é¡ä¼¼ã‚±ãƒ¼ã‚¹ã§ã®é–“é•ã„ã‚’äºˆé˜²
"""
import sys
from pathlib import Path
from datetime import datetime
import json
from typing import Dict, Any, List

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’Pythonãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.insert(0, str(Path(__file__).parent.parent))

from scripts.feedback_manager import FeedbackManager, create_feedback_enhanced_analyzer
from scripts.abstract_learner import AbstractLearner, PreventiveLearner


class AdvancedBusinessAnalyzer:
    """æŠ½è±¡åŒ–å­¦ç¿’æ©Ÿèƒ½ã‚’æŒã¤é«˜åº¦ãªã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼"""
    
    def __init__(self):
        self.base_analyzer = create_feedback_enhanced_analyzer()
        self.feedback_manager = FeedbackManager()
        self.abstract_learner = AbstractLearner()
        self.preventive_learner = PreventiveLearner(self.abstract_learner)
        
        # æ—¢å­˜ã®ä¿®æ­£å±¥æ­´ã‹ã‚‰æŠ½è±¡çš„ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å­¦ç¿’
        self._learn_from_history()
    
    def _learn_from_history(self):
        """éå»ã®ä¿®æ­£å±¥æ­´ã‹ã‚‰å­¦ç¿’"""
        knowledge_base = self.feedback_manager.knowledge_base
        corrections = knowledge_base.get('corrections', [])
        
        if corrections:
            print("ğŸ“š éå»ã®ä¿®æ­£å±¥æ­´ã‹ã‚‰å­¦ç¿’ä¸­...")
            self.abstract_learner.learn_from_corrections(corrections)
            print("âœ… æŠ½è±¡çš„ãƒ‘ã‚¿ãƒ¼ãƒ³ã®å­¦ç¿’å®Œäº†\n")
    
    def analyze_with_prevention(self, file_path: Path) -> Dict[str, Any]:
        """äºˆé˜²çš„ãªåˆ†æã‚’å®Ÿè¡Œ"""
        print(f"\nğŸ” {file_path.name} ã‚’é«˜åº¦ãªåˆ†æä¸­...\n")
        
        # åŸºæœ¬åˆ†æ
        analysis = self.base_analyzer.analyze_with_claude(file_path)
        
        # æŠ½è±¡çš„çŸ¥è­˜ã‚’é©ç”¨
        print("ğŸ§  æŠ½è±¡çš„ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’é©ç”¨ä¸­...")
        enhanced_analysis = self.abstract_learner.apply_abstract_knowledge(analysis)
        
        # æ½œåœ¨çš„ã‚¨ãƒ©ãƒ¼ã‚’æ¤œå‡º
        warnings = self.preventive_learner.analyze_potential_errors(enhanced_analysis)
        
        if warnings:
            print("\nâš ï¸  æ½œåœ¨çš„ãªå•é¡Œã‚’æ¤œå‡ºã—ã¾ã—ãŸ:")
            print("=" * 60)
            suggestions = self.preventive_learner.suggest_verifications(warnings)
            for suggestion in suggestions:
                print(suggestion)
            print("=" * 60)
            
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ç¢ºèªã‚’ä¿ƒã™
            self._interactive_verification(enhanced_analysis, warnings)
        else:
            print("âœ… é«˜ã„ä¿¡é ¼åº¦ã§åˆ†æå®Œäº†")
        
        # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯åé›†
        final_analysis = self.base_analyzer.feedback_collector.collect_feedback(enhanced_analysis)
        
        # æ–°ã—ã„ä¿®æ­£ãŒã‚ã‚Œã°æŠ½è±¡çš„ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ›´æ–°
        self._update_abstract_patterns()
        
        return final_analysis
    
    def _interactive_verification(self, analysis: Dict[str, Any], warnings: List[Dict]):
        """è­¦å‘Šã«åŸºã¥ã„ã¦å¯¾è©±çš„ã«ç¢ºèª"""
        print("\nç¢ºèªä½œæ¥­ã‚’é–‹å§‹ã—ã¾ã™ã‹ï¼Ÿ (y/n): ", end='')
        if input().lower() == 'y':
            for warning in warnings:
                if warning['type'] == 'name_uncertainty':
                    print(f"\nâ“ {warning['target']}ã®æ­£å¼åç§°ã¯ï¼Ÿ")
                    print("(ã‚ã‹ã‚‰ãªã„å ´åˆã¯Enter): ", end='')
                    full_name = input().strip()
                    if full_name:
                        # åˆ†æçµæœã‚’æ›´æ–°
                        self._update_person_name(analysis, warning['target'], full_name)
                
                elif warning['type'] == 'role_uncertainty':
                    print(f"\nâ“ {warning['target']}ã®æ­£ç¢ºãªå½¹è·ã¯ï¼Ÿ")
                    print(f"ç¾åœ¨: {warning['current']}")
                    print(f"å€™è£œ: {', '.join(warning['alternatives'])}")
                    print("(ã‚ã‹ã‚‰ãªã„å ´åˆã¯Enter): ", end='')
                    role = input().strip()
                    if role:
                        self._update_person_role(analysis, warning['target'], role)
    
    def _update_person_name(self, analysis: Dict, old_name: str, new_name: str):
        """äººç‰©åã‚’æ›´æ–°"""
        for person in analysis.get('identified_persons', []):
            if person['name'] == old_name:
                person['name'] = new_name
                person['name_confidence'] = 1.0
                break
    
    def _update_person_role(self, analysis: Dict, name: str, new_role: str):
        """å½¹è·ã‚’æ›´æ–°"""
        for person in analysis.get('identified_persons', []):
            if person['name'] == name:
                person['role'] = new_role
                person['role_confidence'] = 1.0
                break
    
    def _update_abstract_patterns(self):
        """æ–°ã—ã„ä¿®æ­£ã‹ã‚‰æŠ½è±¡çš„ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å­¦ç¿’"""
        # æœ€æ–°ã®ä¿®æ­£ã‚’å–å¾—
        recent_corrections = self.feedback_manager.knowledge_base.get('corrections', [])[-5:]
        if recent_corrections:
            self.abstract_learner.learn_from_corrections(recent_corrections)
    
    def show_learning_status(self):
        """å­¦ç¿’çŠ¶æ³ã‚’è¡¨ç¤º"""
        print("\n" + "=" * 60)
        print("ğŸ“ é«˜åº¦ãªå­¦ç¿’çŠ¶æ³")
        print("=" * 60)
        
        # åŸºæœ¬çš„ãªå­¦ç¿’å†…å®¹
        print("\n" + self.feedback_manager.generate_feedback_report())
        
        # æŠ½è±¡çš„ãªå­¦ç¿’å†…å®¹
        print("\n" + self.abstract_learner.generate_learning_report())
        
        print("\n" + "=" * 60)


def demonstrate_abstract_learning():
    """æŠ½è±¡åŒ–å­¦ç¿’ã®ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"""
    print("ğŸ¯ æŠ½è±¡åŒ–å­¦ç¿’ã®ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³")
    print("=" * 60)
    
    # ã‚·ãƒŠãƒªã‚ª1: åå‰ã®çœç•¥ãƒ‘ã‚¿ãƒ¼ãƒ³
    print("\nğŸ“Œ ã‚·ãƒŠãƒªã‚ª1: åå‰ã®çœç•¥ãƒ‘ã‚¿ãƒ¼ãƒ³")
    print("å…·ä½“ä¾‹:")
    print("  - ã¾ã‚† â†’ å››ãƒå®®ã¾ã‚†")
    print("  - ã‚Šã‚‡ã†ãŸ â†’ è…é‡éš†å¤ª")
    print("æŠ½è±¡åŒ–:")
    print("  â†’ ã€Œãƒ“ã‚¸ãƒã‚¹æ–‡æ›¸ã§ã¯å§“åãƒ•ãƒ«ãƒãƒ¼ãƒ ãŒåŸºæœ¬ã€")
    print("å¿œç”¨:")
    print("  â†’ æ¬¡å›ã€ŒãŸã‘ã—ã€ã‚’è¦‹ãŸã‚‰ã€Œâ—‹â—‹ãŸã‘ã—ã€ã®å¯èƒ½æ€§ã‚’ç¤ºå”†")
    
    # ã‚·ãƒŠãƒªã‚ª2: å½¹è·ã®éå°è©•ä¾¡ãƒ‘ã‚¿ãƒ¼ãƒ³
    print("\nğŸ“Œ ã‚·ãƒŠãƒªã‚ª2: å½¹è·ã®éå°è©•ä¾¡ãƒ‘ã‚¿ãƒ¼ãƒ³")
    print("å…·ä½“ä¾‹:")
    print("  - è…é‡: PM â†’ ç¤¾é•·")
    print("  - å²¡ï¨‘: æ‹…å½“è€… â†’ ä»£è¡¨")
    print("æŠ½è±¡åŒ–:")
    print("  â†’ ã€Œå°è¦æ¨¡ä¼æ¥­ã§ã¯ä»£è¡¨è€…ãŒç›´æ¥å¯¾å¿œã€")
    print("å¿œç”¨:")
    print("  â†’ å°‘äººæ•°ã§ã®ç›´æ¥ã‚„ã‚Šå–ã‚Š â†’ ä¸Šä½å½¹è·è€…ã®å¯èƒ½æ€§å¤§")
    
    # ã‚·ãƒŠãƒªã‚ª3: çµ„ç¹”æ‰€å±ã®èª¤èªãƒ‘ã‚¿ãƒ¼ãƒ³
    print("\nğŸ“Œ ã‚·ãƒŠãƒªã‚ª3: çµ„ç¹”æ‰€å±ã®èª¤èªãƒ‘ã‚¿ãƒ¼ãƒ³")
    print("å…·ä½“ä¾‹:")
    print("  - æœ«æ­¦: AGOç¤¾å“¡ â†’ ãƒ•ãƒªãƒ¼ãƒ©ãƒ³ã‚¹")
    print("æŠ½è±¡åŒ–:")
    print("  â†’ ã€Œè¤‡æ•°çµ„ç¹”ã‚’ä»²ä»‹ã™ã‚‹äººç‰©ã¯å¤–éƒ¨ã®å¯èƒ½æ€§ã€")
    print("å¿œç”¨:")
    print("  â†’ ä»²ä»‹çš„ãªå‹•ãã‚’æ¤œå‡º â†’ ãƒ•ãƒªãƒ¼ãƒ©ãƒ³ã‚¹ã®å¯èƒ½æ€§ã‚’è­¦å‘Š")


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    if len(sys.argv) > 1 and sys.argv[1] == "--demo":
        demonstrate_abstract_learning()
        return
    
    print("ğŸš€ AGO Group é«˜åº¦ãªæ¥­å‹™åˆ†æã‚·ã‚¹ãƒ†ãƒ ï¼ˆæŠ½è±¡åŒ–å­¦ç¿’æ©Ÿèƒ½ä»˜ãï¼‰")
    print("=" * 60)
    
    analyzer = AdvancedBusinessAnalyzer()
    
    # å­¦ç¿’çŠ¶æ³ã‚’è¡¨ç¤º
    analyzer.show_learning_status()
    
    # ãƒ•ã‚¡ã‚¤ãƒ«é¸æŠ
    raw_files = list(Path("data/raw").rglob("*.txt"))
    if not raw_files:
        print("\nâŒ data/raw/ ã«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return
    
    print(f"\nğŸ“ {len(raw_files)}å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ")
    for i, file in enumerate(raw_files, 1):
        print(f"{i}. {file.name}")
    
    choice = input("\nåˆ†æã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ç•ªå·: ")
    try:
        selected_file = raw_files[int(choice) - 1]
    except (ValueError, IndexError):
        print("âŒ ç„¡åŠ¹ãªé¸æŠã§ã™")
        return
    
    # é«˜åº¦ãªåˆ†æã‚’å®Ÿè¡Œ
    try:
        analysis = analyzer.analyze_with_prevention(selected_file)
        
        # çµæœã‚’ä¿å­˜
        output_dir = Path("output/advanced_analysis")
        output_dir.mkdir(parents=True, exist_ok=True)
        
        output_file = output_dir / f"{selected_file.stem}_analysis.json"
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(analysis, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ’¾ åˆ†æçµæœã‚’ä¿å­˜: {output_file}")
        print("\nâœ… é«˜åº¦ãªåˆ†æå®Œäº†ï¼å­¦ç¿’å†…å®¹ã¯æ¬¡å›ã®åˆ†æã§ã•ã‚‰ã«è³¢ãæ´»ç”¨ã•ã‚Œã¾ã™")
        
    except KeyboardInterrupt:
        print("\n\nâš ï¸ åˆ†æã‚’ä¸­æ–­ã—ã¾ã—ãŸ")
    except Exception as e:
        print(f"\nâŒ ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()