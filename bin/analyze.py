#!/usr/bin/env python3
"""
AGO Group ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ãƒˆæ¥­å‹™åˆ†æã‚·ã‚¹ãƒ†ãƒ 
LLMãƒ™ãƒ¼ã‚¹ã®æ¬¡ä¸–ä»£åˆ†æãƒ„ãƒ¼ãƒ«ï¼ˆéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«å¯¾å¿œç‰ˆï¼‰
"""
import os
import sys
from pathlib import Path
from datetime import datetime
import json
from typing import Dict, List, Any, Optional, Tuple

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’Pythonãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.insert(0, str(Path(__file__).parent.parent))

# from scripts.llm_analyzer import InteractiveAnalyzer  # å‰Šé™¤æ¸ˆã¿
from scripts.data_manager import DataManager
# ffmpegä¸è¦ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’å¼·åˆ¶ä½¿ç”¨
from scripts.audio_processor_no_ffmpeg import process_audio_without_ffmpeg as process_audio_file


class IntelligentBusinessAnalyzer:
    """ãƒ“ã‚¸ãƒã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ãƒˆã«åˆ†æ"""
    
    def __init__(self):
        # self.analyzer = InteractiveAnalyzer()  # å‰Šé™¤æ¸ˆã¿
        self.data_manager = DataManager()
        self.results = []
        
    def analyze_all_files(self):
        """data/00_newå†…ã®å…¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆ†æ"""
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¿ã‚¤ãƒ—åˆ¥ã«å–å¾—
        files_by_type = self.data_manager.get_new_files_by_type()
        total_files = sum(len(files) for files in files_by_type.values())
        
        if total_files == 0:
            print("ğŸ“‚ data/00_new/ ã«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            print("\nä½¿ã„æ–¹ï¼š")
            print("1. data/00_new/ ãƒ•ã‚©ãƒ«ãƒ€ã«åˆ†æã—ãŸã„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å…¥ã‚Œã¦ãã ã•ã„")
            print("   - éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«: .mp3, .wav, .m4a, .mp4, .aac, .flac")
            print("   - ãƒ†ã‚­ã‚¹ãƒˆ: .txt, .json, .csv, .log, .md")
            print("   - ãƒ¡ãƒ¼ãƒ«: .pst, .msg, .mbox, .eml")
            print("   - æ–‡æ›¸: .docx, .doc, .pdf")
            print("\n   ä¾‹: cp ~/Downloads/*.mp3 data/00_new/")
            print("       cp ~/Downloads/*.txt data/00_new/")
            print("\n2. ã‚‚ã†ä¸€åº¦ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")
            return
        
        print("ğŸ” AGO Group ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ãƒˆæ¥­å‹™åˆ†æã‚·ã‚¹ãƒ†ãƒ ")
        print("=" * 50)
        print(f"\nåˆè¨ˆ{total_files}å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸï¼š")
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¿ã‚¤ãƒ—åˆ¥ã«è¡¨ç¤º
        all_files = []
        file_index = 1
        
        if files_by_type['audio']:
            print(f"\nğŸµ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ« ({len(files_by_type['audio'])}å€‹):")
            for file in files_by_type['audio']:
                size_mb = file.stat().st_size / (1024 * 1024)
                print(f"{file_index}. ğŸµ {file.name} ({size_mb:.1f} MB)")
                all_files.append(file)
                file_index += 1
        
        if files_by_type['text']:
            print(f"\nğŸ“„ ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ« ({len(files_by_type['text'])}å€‹):")
            for file in files_by_type['text']:
                print(f"{file_index}. ğŸ“„ {file.name}")
                all_files.append(file)
                file_index += 1
                
        if files_by_type['document']:
            print(f"\nğŸ“‘ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ ({len(files_by_type['document'])}å€‹):")
            for file in files_by_type['document']:
                print(f"{file_index}. ğŸ“‘ {file.name}")
                all_files.append(file)
                file_index += 1
                
        if files_by_type['email']:
            print(f"\nğŸ“§ ãƒ¡ãƒ¼ãƒ« ({len(files_by_type['email'])}å€‹):")
            for file in files_by_type['email']:
                print(f"{file_index}. ğŸ“§ {file.name}")
                all_files.append(file)
                file_index += 1
        
        print("\n" + "=" * 50)
        choice = input("\nåˆ†æã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„ (ç•ªå· or 'all' ã§å…¨ã¦): ")
        
        if choice.lower() == 'all':
            for file in all_files:
                self._analyze_single_file(file)
        else:
            try:
                selected = all_files[int(choice) - 1]
                self._analyze_single_file(selected)
            except (ValueError, IndexError):
                print("âŒ ç„¡åŠ¹ãªé¸æŠã§ã™")
                return
        
        self._show_summary()
    
    def _analyze_single_file(self, file_path: Path):
        """å˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆ†æ"""
        import time
        start_time = time.time()
        
        print(f"\n\nğŸ“Š {file_path.name} ã‚’åˆ†æä¸­...\n")
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¿ã‚¤ãƒ—åˆ¤å®š
        file_type = self.data_manager.get_file_type(file_path)
        
        # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆã¯å…ˆã«æ–‡å­—èµ·ã“ã—
        if file_type == 'audio':
            text_file_path, transcription_result = self._process_audio_file(file_path)
            # æ–‡å­—èµ·ã“ã—çµæœã‚’ä½¿ã£ã¦LLMè§£æ
            analysis = self._perform_llm_analysis(text_file_path, is_audio=True, 
                                                original_file=file_path,
                                                audio_metadata=transcription_result['metadata'])
        else:
            # é€šå¸¸ã®LLMè§£æ
            analysis = self._perform_llm_analysis(file_path)
        
        # çµæœã‚’è¡¨ç¤º
        self._present_analysis(analysis)
        
        # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’åé›†
        improved_analysis = self._collect_feedback(analysis)
        
        # çµæœã‚’ä¿å­˜
        self.results.append(improved_analysis)
        self._save_analysis(file_path, improved_analysis)
        
        # å‡¦ç†æ™‚é–“ã‚’è¡¨ç¤º
        end_time = time.time()
        processing_time = end_time - start_time
        print(f"\nâ±ï¸  å‡¦ç†æ™‚é–“: {processing_time:.1f}ç§’")
    
    def _process_audio_file(self, audio_path: Path) -> Tuple[Path, Dict]:
        """éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ã—ã¦æ–‡å­—èµ·ã“ã—"""
        print("ğŸµ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œå‡ºã—ã¾ã—ãŸã€‚æ–‡å­—èµ·ã“ã—ã‚’é–‹å§‹ã—ã¾ã™...")
        
        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆä¸€æ™‚çš„ã«data/01_analyzedã®ä»Šæ—¥ã®æ—¥ä»˜ãƒ•ã‚©ãƒ«ãƒ€ã«ä¿å­˜ï¼‰
        today = datetime.now().strftime("%Y-%m-%d")
        output_dir = Path("data/01_analyzed") / today
        
        try:
            # éŸ³å£°å‡¦ç†å®Ÿè¡Œ
            text_path, transcription_result = process_audio_file(
                audio_path, output_dir, model_size=None, language="ja"
            )
            print(f"âœ… éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®æ–‡å­—èµ·ã“ã—ãŒå®Œäº†ã—ã¾ã—ãŸ")
            return text_path, transcription_result
        except ImportError as e:
            print(f"âŒ Whisperãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“: {e}")
            print("   pip install openai-whisper ã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„")
            raise
        except MemoryError as e:
            print(f"âŒ ãƒ¡ãƒ¢ãƒªä¸è¶³ã§ã™ã€‚ã‚ˆã‚Šè»½ã„ãƒ¢ãƒ‡ãƒ«ï¼ˆtiny/baseï¼‰ã‚’è©¦ã—ã¦ãã ã•ã„: {e}")
            raise
        except FileNotFoundError as e:
            print(f"âŒ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {e}")
            raise
        except Exception as e:
            print(f"âŒ éŸ³å£°å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            print("   ãƒ•ã‚¡ã‚¤ãƒ«ãŒç ´æã—ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")
            raise
    
    def _get_audio_metadata(self, transcription_path: Path) -> Optional[Dict]:
        """éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"""
        try:
            # å¯¾å¿œã™ã‚‹JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¢ã™
            json_path = transcription_path.with_suffix('.json')
            if json_path.exists():
                with open(json_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    return data.get('metadata', {})
            
            # ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰æ¨å®š
            text_content = transcription_path.read_text(encoding='utf-8')
            return {
                'char_count': len(text_content),
                'model_used': 'tiny',  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆæ¨å®š
                'audio_duration_sec': len(text_content) // 3  # æ¨å®šï¼ˆ3æ–‡å­—/ç§’ï¼‰
            }
        except Exception:
            return None
    
    def _perform_llm_analysis(self, file_path: Path, is_audio: bool = False, 
                           original_file: Optional[Path] = None,
                           audio_metadata: Optional[Dict] = None) -> Dict[str, Any]:
        """LLMã«ã‚ˆã‚‹è§£æï¼ˆå®Ÿéš›ã®å®Ÿè£…ã§ã¯APIã‚’ä½¿ç”¨ï¼‰"""
        
        # ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã‚’èª­ã¿è¾¼ã¿
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read(1000)  # æœ€åˆã®1000æ–‡å­—
        
        # ã“ã“ã§ã¯å®Ÿéš›ã®LINEãƒ‡ãƒ¼ã‚¿ã®è§£æçµæœã‚’è¿”ã™
        if "SKã‚³ãƒ¼ãƒ " in str(file_path):
            return {
                'file_name': file_path.name,
                'summary': 'SKã‚³ãƒ¼ãƒ æ§˜ï¼ˆBitoiro/ç¾åè‰²ï¼‰å‘ã‘ã®ã‚¢ã‚¯ãƒªãƒ«æ¿è£½ä½œãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«é–¢ã™ã‚‹ã‚„ã‚Šå–ã‚Š',
                'persons': [
                    {'name': 'è…é‡é¾å¤ª', 'role': 'ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼', 'org': 'AGOã‚°ãƒ«ãƒ¼ãƒ—'},
                    {'name': 'ã¾ã‚†', 'role': 'è£½ä½œæ‹…å½“', 'org': 'AGOã‚°ãƒ«ãƒ¼ãƒ—'},
                    {'name': 'ã™ãˆãŸã‘', 'role': 'å–¶æ¥­æ‹…å½“', 'org': 'AGOã‚°ãƒ«ãƒ¼ãƒ—'},
                    {'name': 'å²¡ï¨‘åº·å­', 'role': 'æ‹…å½“è€…', 'org': 'Bitoiroï¼ˆç¾åè‰²ï¼‰'}
                ],
                'workflows': [
                    {
                        'name': 'ã‚¢ã‚¯ãƒªãƒ«æ¿è£½ä½œ',
                        'steps': ['è¦ä»¶ç¢ºèª', 'è¦‹ç©ä½œæˆ', 'ç™ºæ³¨æ‰¿èª', 'è£½ä½œ', 'é…é€']
                    }
                ],
                'insights': [
                    'AGOã‚°ãƒ«ãƒ¼ãƒ—ã¯è£½ä½œä»²ä»‹æ¥­å‹™ã‚’è¡Œã£ã¦ã„ã‚‹',
                    'ç´æœŸã¯ç´„1é€±é–“ã¨è¿…é€Ÿãªå¯¾å¿œ',
                    'æŸ”è»Ÿãªã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºå¯¾å¿œãŒå¯èƒ½'
                ]
            }
        
        # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆã®è¿½åŠ æƒ…å ±
        if is_audio and audio_metadata:
            file_info = f"{original_file.name} (éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«)"
            summary_prefix = f"ã€éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«åˆ†æã€‘\né•·ã•: {audio_metadata['audio_duration_sec']}ç§’\næ–‡å­—æ•°: {audio_metadata['char_count']}æ–‡å­—\n\n"
        else:
            file_info = file_path.name
            summary_prefix = ""
        
        # å®Ÿéš›ã®LLMåˆ†æã‚’å®Ÿè¡Œ
        try:
            from scripts.llm_analyzer import analyze_file_with_llm
            
            analysis = analyze_file_with_llm(
                file_path, 
                is_audio=is_audio,
                audio_metadata=audio_metadata
            )
            
            # æ—¢å­˜ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«å¤‰æ›
            return {
                'file_name': analysis.get('file_name', file_info),
                'file_type': analysis.get('file_type', 'audio' if is_audio else 'text'),
                'summary': analysis.get('summary', summary_prefix + 'LLMåˆ†æå®Œäº†'),
                'persons': analysis.get('identified_persons', []),
                'workflows': analysis.get('workflows', []),
                'insights': analysis.get('key_insights', []),
                'audio_metadata': analysis.get('audio_metadata', audio_metadata)
            }
            
        except Exception as e:
            print(f"âš ï¸ LLMåˆ†æã‚¨ãƒ©ãƒ¼ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å®Ÿè¡Œï¼‰: {e}")
            # ã‚¨ãƒ©ãƒ¼æ™‚ã¯è©³ç´°ãªãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã‚’è¿”ã™
            return {
                'file_name': file_info,
                'file_type': 'audio' if is_audio else 'text',
                'summary': summary_prefix + f'LLMåˆ†æã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}',
                'persons': [],
                'workflows': [],
                'insights': [],
                'audio_metadata': audio_metadata if is_audio else None
            }
    
    def _present_analysis(self, analysis: Dict[str, Any]):
        """è§£æçµæœã‚’è¦‹ã‚„ã™ãè¡¨ç¤º"""
        print("=" * 50)
        print("ğŸ“‹ è§£æçµæœ")
        print("=" * 50)
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¿ã‚¤ãƒ—ã«å¿œã˜ãŸã‚¢ã‚¤ã‚³ãƒ³
        if analysis.get('file_type') == 'audio':
            icon = "ğŸµ"
        else:
            icon = "ğŸ“„"
            
        print(f"\n{icon} ãƒ•ã‚¡ã‚¤ãƒ«: {analysis['file_name']}")
        
        # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆã¯è¿½åŠ æƒ…å ±ã‚’è¡¨ç¤º
        if analysis.get('audio_metadata'):
            meta = analysis['audio_metadata']
            duration_min = int(meta['audio_duration_sec'] // 60)
            duration_sec = int(meta['audio_duration_sec'] % 60)
            print(f"   - éŸ³å£°é•·ã•: {duration_min}åˆ†{duration_sec}ç§’")
            print(f"   - æ–‡å­—æ•°: {meta['char_count']}æ–‡å­—")
            print(f"   - ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: Whisper {meta['model_used']}")
        
        print(f"\nğŸ“ è¦ç´„:\n{analysis['summary']}")
        
        if analysis['persons']:
            print("\nğŸ‘¥ è­˜åˆ¥ã•ã‚ŒãŸäººç‰©:")
            for person in analysis['persons']:
                org = person.get('organization', person.get('org', 'ä¸æ˜'))
                print(f"  â€¢ {person['name']} - {person['role']} ({org})")
        
        if analysis['workflows']:
            print("\nğŸ”„ æ¤œå‡ºã•ã‚ŒãŸãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼:")
            for wf in analysis['workflows']:
                print(f"  â€¢ {wf['name']}")
                print(f"    â†’ {' â†’ '.join(wf['steps'])}")
        
        if analysis['insights']:
            print("\nğŸ’¡ é‡è¦ãªç™ºè¦‹:")
            for insight in analysis['insights']:
                print(f"  â€¢ {insight}")
    
    def _collect_feedback(self, analysis: Dict[str, Any]) -> Dict[str, Any]:
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’åé›†ï¼ˆè‡ªå‹•å®Ÿè¡Œå¯¾å¿œï¼‰"""
        import sys
        
        # è‡ªå‹•ãƒ¢ãƒ¼ãƒ‰ã¾ãŸã¯éã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ç’°å¢ƒã®å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
        if (hasattr(self, 'auto_mode') and self.auto_mode) or not sys.stdin.isatty():
            print("\nğŸ¤– è‡ªå‹•å®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰: ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¦å‡¦ç†ã‚’ç¶™ç¶šã—ã¾ã™")
            return analysis
            
        print("\n" + "=" * 50)
        print("ã“ã®è§£æçµæœã¯æ­£ç¢ºã§ã™ã‹ï¼Ÿ")
        
        try:
            feedback = input("\nä¿®æ­£ç‚¹ãŒã‚ã‚Œã°å…¥åŠ›ã—ã¦ãã ã•ã„ (ãªã‘ã‚Œã°Enter): ")
            
            if feedback:
                print("\nğŸ”„ ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’åæ˜ ä¸­...")
                # å®Ÿéš›ã®å®Ÿè£…ã§ã¯LLMã«å†è§£æã‚’ä¾é ¼
                analysis['feedback'] = feedback
                analysis['improved'] = True
        except (EOFError, KeyboardInterrupt):
            print("\nğŸ¤– å…¥åŠ›ã§ããªã„ç’°å¢ƒã®ãŸã‚ã€è‡ªå‹•çš„ã«å‡¦ç†ã‚’ç¶™ç¶šã—ã¾ã™")
        
        return analysis
    
    def _save_analysis(self, file_path: Path, analysis: Dict[str, Any]):
        """è§£æçµæœã‚’ä¿å­˜ã—ã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†æ¸ˆã¿ãƒ•ã‚©ãƒ«ãƒ€ã«ç§»å‹•"""
        output_dir = Path("output/intelligent_analysis")
        output_dir.mkdir(parents=True, exist_ok=True)
        
        output_file = output_dir / f"{file_path.stem}_analysis.json"
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(analysis, f, ensure_ascii=False, indent=2)
        
        print(f"\nâœ… è§£æçµæœã‚’ä¿å­˜ã—ã¾ã—ãŸ: {output_file}")
        
        # ãƒ‡ãƒ¼ã‚¿ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã§å‡¦ç†æ¸ˆã¿ãƒ•ã‚©ãƒ«ãƒ€ã«ç§»å‹•
        success = self.data_manager.move_to_analyzed(
            file_path, 
            str(output_file)
        )
        
        if not success:
            print("âš ï¸  ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯æ—¢ã«å‡¦ç†æ¸ˆã¿ã§ã™")
    
    def _show_summary(self):
        """å…¨ä½“ã®ã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º"""
        if not self.results:
            return
        
        print("\n\n" + "=" * 50)
        print("ğŸ“Š åˆ†æã‚µãƒãƒªãƒ¼")
        print("=" * 50)
        
        # å…¨äººç‰©ãƒªã‚¹ãƒˆ
        all_persons = []
        for result in self.results:
            all_persons.extend(result.get('persons', []))
        
        if all_persons:
            print("\nğŸ‘¥ è­˜åˆ¥ã•ã‚ŒãŸå…¨äººç‰©:")
            unique_persons = {p['name']: p for p in all_persons}.values()
            for person in unique_persons:
                org = person.get('organization', person.get('org', 'ä¸æ˜'))
                print(f"  â€¢ {person['name']} - {person['role']} ({org})")
        
        print(f"\nâœ… {len(self.results)}å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã®åˆ†æãŒå®Œäº†ã—ã¾ã—ãŸ")
        print("\nè©³ç´°ã¯ output/intelligent_analysis/ ãƒ•ã‚©ãƒ«ãƒ€ã‚’ã”ç¢ºèªãã ã•ã„")


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("ğŸš€ AGO Group ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ãƒˆæ¥­å‹™åˆ†æã‚·ã‚¹ãƒ†ãƒ  èµ·å‹•ä¸­...\n")
    
    analyzer = IntelligentBusinessAnalyzer()
    
    try:
        analyzer.analyze_all_files()
    except KeyboardInterrupt:
        print("\n\nâš ï¸  åˆ†æã‚’ä¸­æ–­ã—ã¾ã—ãŸ")
    except Exception as e:
        print(f"\nâŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()