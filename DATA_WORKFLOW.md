# ğŸ“Š AGOã‚°ãƒ«ãƒ¼ãƒ— ãƒ‡ãƒ¼ã‚¿ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ç®¡ç†

## æ¨å¥¨ãƒ‡ãƒ¼ã‚¿ç®¡ç†æ§‹é€ 

```
data/
â”œâ”€â”€ 00_new/          # ğŸ†• æ–°è¦ãƒ‡ãƒ¼ã‚¿æŠ•å…¥ï¼ˆã“ã“ã«å…¥ã‚Œã‚‹ï¼‰
â”œâ”€â”€ 01_analyzed/     # âœ… åˆ†ææ¸ˆã¿ãƒ‡ãƒ¼ã‚¿
â”‚   â”œâ”€â”€ 2025-01-13/  # å‡¦ç†æ—¥ã”ã¨ã«æ•´ç†
â”‚   â””â”€â”€ 2025-01-14/
â”œâ”€â”€ 02_archive/      # ğŸ“¦ ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ï¼ˆ6ãƒ¶æœˆä»¥ä¸Šå‰ï¼‰
â””â”€â”€ analysis_log.json # ğŸ“ å‡¦ç†å±¥æ­´
```

## ğŸ”„ ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼

### 1. ãƒ‡ãƒ¼ã‚¿æŠ•å…¥
```bash
# æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã¯å¿…ãš 00_new ã¸
cp ~/Downloads/æ–°ã—ã„LINE.txt data/00_new/
```

### 2. åˆ†æå®Ÿè¡Œ
```bash
python analyze.py
# ã‚·ã‚¹ãƒ†ãƒ ãŒè‡ªå‹•çš„ã« 00_new å†…ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†
```

### 3. è‡ªå‹•æ•´ç†
åˆ†æå®Œäº†å¾Œã€ã‚·ã‚¹ãƒ†ãƒ ãŒè‡ªå‹•çš„ã«ï¼š
- å‡¦ç†æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ—¥ä»˜ãƒ•ã‚©ãƒ«ãƒ€ã¸ç§»å‹•
- analysis_log.json ã«è¨˜éŒ²

### 4. å®šæœŸã‚¢ãƒ¼ã‚«ã‚¤ãƒ–
```bash
# 6ãƒ¶æœˆä»¥ä¸Šå‰ã®ãƒ‡ãƒ¼ã‚¿ã‚’è‡ªå‹•ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–
python archive_old_data.py
```

## ğŸ“ å‡¦ç†å±¥æ­´ã®ç®¡ç†

### analysis_log.json ã®æ§‹é€ 
```json
{
  "processed_files": [
    {
      "filename": "[LINE]å–¶æ¥­ãƒãƒ¼ãƒ .txt",
      "original_path": "data/00_new/[LINE]å–¶æ¥­ãƒãƒ¼ãƒ .txt",
      "processed_date": "2025-01-13 14:30:00",
      "moved_to": "data/01_analyzed/2025-01-13/",
      "analysis_results": "output/intelligent_analysis/å–¶æ¥­ãƒãƒ¼ãƒ _analysis.json",
      "file_hash": "a1b2c3d4e5f6",
      "status": "completed"
    }
  ]
}
```

## ğŸš¨ é‡è¤‡ãƒã‚§ãƒƒã‚¯æ©Ÿèƒ½

### ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒƒã‚·ãƒ¥ã«ã‚ˆã‚‹é‡è¤‡é˜²æ­¢
```python
def check_duplicate(file_path):
    """æ—¢ã«å‡¦ç†æ¸ˆã¿ã‹ãƒã‚§ãƒƒã‚¯"""
    file_hash = calculate_hash(file_path)
    
    with open('data/analysis_log.json', 'r') as f:
        log = json.load(f)
    
    for record in log['processed_files']:
        if record['file_hash'] == file_hash:
            return True, record['processed_date']
    
    return False, None
```

## ğŸ’¡ ãƒ¡ãƒªãƒƒãƒˆ

1. **æ˜ç¢ºãªçŠ¶æ…‹ç®¡ç†**
   - æ–°è¦: 00_new ã«ã‚ã‚‹ã‚‚ã®
   - å‡¦ç†æ¸ˆã¿: 01_analyzed ã«ã‚ã‚‹ã‚‚ã®
   - å¤ã„: 02_archive ã«ã‚ã‚‹ã‚‚ã®

2. **å‡¦ç†å±¥æ­´ã®è¿½è·¡**
   - ã„ã¤å‡¦ç†ã—ãŸã‹
   - ã©ã®åˆ†æçµæœã‹
   - é‡è¤‡å‡¦ç†ã®é˜²æ­¢

3. **å®¹é‡ç®¡ç†**
   - å¤ã„ãƒ‡ãƒ¼ã‚¿ã®è‡ªå‹•ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–
   - å¿…è¦ã«å¿œã˜ã¦å‰Šé™¤å¯èƒ½

## ğŸ› ï¸ å®Ÿè£…ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

### data_manager.py
```python
#!/usr/bin/env python3
"""ãƒ‡ãƒ¼ã‚¿ç®¡ç†ãƒ˜ãƒ«ãƒ‘ãƒ¼"""

import os
import shutil
import json
import hashlib
from datetime import datetime, timedelta
from pathlib import Path

class DataManager:
    def __init__(self):
        self.new_dir = Path("data/00_new")
        self.analyzed_dir = Path("data/01_analyzed")
        self.archive_dir = Path("data/02_archive")
        self.log_file = Path("data/analysis_log.json")
        
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        for dir in [self.new_dir, self.analyzed_dir, self.archive_dir]:
            dir.mkdir(parents=True, exist_ok=True)
            
        # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«åˆæœŸåŒ–
        if not self.log_file.exists():
            self.log_file.write_text('{"processed_files": []}')
    
    def get_new_files(self):
        """æœªå‡¦ç†ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒªã‚¹ãƒˆã‚’å–å¾—"""
        return list(self.new_dir.glob("*"))
    
    def move_to_analyzed(self, file_path, analysis_result_path):
        """å‡¦ç†æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç§»å‹•"""
        today = datetime.now().strftime("%Y-%m-%d")
        dest_dir = self.analyzed_dir / today
        dest_dir.mkdir(exist_ok=True)
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ç§»å‹•
        dest_path = dest_dir / file_path.name
        shutil.move(str(file_path), str(dest_path))
        
        # ãƒ­ã‚°æ›´æ–°
        self._update_log(file_path, dest_path, analysis_result_path)
        
    def archive_old_files(self, days=180):
        """å¤ã„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–"""
        cutoff_date = datetime.now() - timedelta(days=days)
        
        for date_dir in self.analyzed_dir.iterdir():
            if date_dir.is_dir():
                dir_date = datetime.strptime(date_dir.name, "%Y-%m-%d")
                if dir_date < cutoff_date:
                    shutil.move(str(date_dir), str(self.archive_dir))
                    print(f"Archived: {date_dir.name}")
```

## ğŸ¯ é‹ç”¨ãƒ«ãƒ¼ãƒ«

1. **æ–°è¦ãƒ‡ãƒ¼ã‚¿ã¯å¿…ãš `00_new` ã¸**
2. **åˆ†æå¾Œã¯è‡ªå‹•ã§ `01_analyzed/æ—¥ä»˜/` ã¸**
3. **6ãƒ¶æœˆå¾Œã«è‡ªå‹•ã§ `02_archive` ã¸**
4. **1å¹´å¾Œã«ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã‹ã‚‰å‰Šé™¤æ¤œè¨**

ã“ã‚Œã§ã€ã©ã®ãƒ‡ãƒ¼ã‚¿ãŒå‡¦ç†æ¸ˆã¿ã‹ä¸€ç›®ç­ç„¶ã«ãªã‚Šã¾ã™ï¼