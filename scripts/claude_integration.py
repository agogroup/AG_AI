#!/usr/bin/env python3
"""
Claude Codeçµ±åˆå‹LLMåˆ†æã‚·ã‚¹ãƒ†ãƒ 
Claude Codeã®å¯¾è©±æ©Ÿèƒ½ã‚’æ´»ç”¨ã—ã¦ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ åˆ†æã‚’å®Ÿç¾
"""
import json
import sys
from pathlib import Path
from typing import Dict, Any, List
from datetime import datetime


class ClaudeCodeAnalyzer:
    """Claude Codeã¨é€£æºã—ã¦åˆ†æã‚’è¡Œã†ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.analysis_cache = {}
        
    def analyze_with_claude(self, file_path: Path) -> Dict[str, Any]:
        """Claude Codeã«åˆ†æã‚’ä¾é ¼"""
        print(f"\nğŸ“„ ãƒ•ã‚¡ã‚¤ãƒ«: {file_path.name}")
        print("=" * 60)
        
        # ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã‚’èª­ã¿è¾¼ã¿
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # åˆ†æç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆ
        prompt = self._create_analysis_prompt(content[:2000])  # æœ€åˆã®2000æ–‡å­—
        
        print(prompt)
        print("\n" + "=" * 60)
        print("ğŸ¤– Claude Codeã«ã‚ˆã‚‹åˆ†æ")
        print("=" * 60)
        
        # ã“ã“ã§Claude CodeãŒåˆ†æçµæœã‚’è¡¨ç¤º
        print("\nä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰æ¥­å‹™å†…å®¹ã‚’åˆ†æã—ã¾ã—ãŸï¼š\n")
        
        # ã‚µãƒ³ãƒ—ãƒ«åˆ†æï¼ˆå®Ÿéš›ã®å®Ÿè£…ã§ã¯Claude CodeãŒåˆ†æï¼‰
        if "SKã‚³ãƒ¼ãƒ " in content:
            analysis = {
                "summary": "AGOã‚°ãƒ«ãƒ¼ãƒ—ã¨Bitoiroï¼ˆç¾åè‰²ï¼‰é–“ã®ã‚¢ã‚¯ãƒªãƒ«æ¿è£½ä½œãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«é–¢ã™ã‚‹æ¥­å‹™é€£çµ¡",
                "identified_persons": [
                    {
                        "name": "è…é‡é¾å¤ª", 
                        "role": "ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼",
                        "department": "AGOã‚°ãƒ«ãƒ¼ãƒ—",
                        "activities": ["ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆçµ±æ‹¬", "ãƒãƒ¼ãƒ èª¿æ•´", "ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆå¯¾å¿œ"],
                        "relationships": ["ã¾ã‚†", "ã™ãˆãŸã‘", "å²¡ï¨‘åº·å­"]
                    },
                    {
                        "name": "ã¾ã‚†",
                        "role": "è£½ä½œæ‹…å½“",
                        "department": "AGOã‚°ãƒ«ãƒ¼ãƒ—", 
                        "activities": ["è¦‹ç©ä½œæˆ", "è£½ä½œæ‰‹é…", "ç´æœŸç®¡ç†"],
                        "relationships": ["è…é‡é¾å¤ª", "ã™ãˆãŸã‘"]
                    },
                    {
                        "name": "ã™ãˆãŸã‘",
                        "role": "å–¶æ¥­æ‹…å½“",
                        "department": "AGOã‚°ãƒ«ãƒ¼ãƒ—",
                        "activities": ["é¡§å®¢å¯¾å¿œ", "è¦ä»¶ç¢ºèª", "ç´å“èª¿æ•´"],
                        "relationships": ["è…é‡é¾å¤ª", "ã¾ã‚†", "å²¡ï¨‘åº·å­"]
                    },
                    {
                        "name": "å²¡ï¨‘åº·å­",
                        "role": "ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆæ‹…å½“è€…",
                        "department": "Bitoiroï¼ˆç¾åè‰²ï¼‰",
                        "activities": ["ç™ºæ³¨", "å—å–å¯¾å¿œ"],
                        "relationships": ["ã™ãˆãŸã‘"]
                    }
                ],
                "topics": [
                    "ã‚¢ã‚¯ãƒªãƒ«æ¿ã¸ã®ãƒ‡ã‚¶ã‚¤ãƒ³å°åˆ·",
                    "ã‚«ã‚¹ã‚¿ãƒ ã‚µã‚¤ã‚ºè£½ä½œï¼ˆ330mmÃ—330mmï¼‰", 
                    "ç´æœŸèª¿æ•´ï¼ˆåœŸæ›œæ—¥18æ™‚ä»¥é™é…é€ï¼‰",
                    "è¦‹ç©æ‰¿èªãƒ—ãƒ­ã‚»ã‚¹"
                ],
                "workflows": [
                    {
                        "name": "ã‚¢ã‚¯ãƒªãƒ«æ¿è£½ä½œãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼",
                        "steps": [
                            "ãƒ‡ã‚¶ã‚¤ãƒ³ãƒ‡ãƒ¼ã‚¿å…±æœ‰",
                            "ä»•æ§˜ç¢ºèªï¼ˆã‚µã‚¤ã‚ºãƒ»ã‚«ãƒƒãƒˆãƒ‘ã‚¹ï¼‰",
                            "è¦‹ç©ä½œæˆ",
                            "é¡§å®¢æ‰¿èª",
                            "è£½ä½œæ‰‹é…",
                            "ç´æœŸèª¿æ•´",
                            "é…é€æ‰‹é…"
                        ],
                        "participants": ["è…é‡é¾å¤ª", "ã¾ã‚†", "ã™ãˆãŸã‘", "å²¡ï¨‘åº·å­"]
                    }
                ],
                "key_insights": [
                    "AGOã‚°ãƒ«ãƒ¼ãƒ—ã¯è£½é€ ä»²ä»‹æ¥­å‹™ã‚’æ‹…å½“ï¼ˆè‡ªç¤¾è£½é€ ã§ã¯ãªã„ï¼‰",
                    "è¿…é€Ÿãªå¯¾å¿œï¼ˆè¦‹ç©ã‹ã‚‰ç´å“ã¾ã§ç´„1é€±é–“ï¼‰",
                    "æŸ”è»Ÿãªé…é€å¯¾å¿œï¼ˆæ™‚é–“æŒ‡å®šå¯èƒ½ï¼‰",
                    "å°‘é‡ã‚«ã‚¹ã‚¿ãƒ è£½ä½œã«å¯¾å¿œå¯èƒ½"
                ],
                "confidence_scores": {
                    "persons": 0.95,
                    "workflows": 0.88,
                    "topics": 0.92
                }
            }
        else:
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆåˆ†æ
            analysis = self._get_default_analysis()
            
        return analysis
    
    def _create_analysis_prompt(self, content: str) -> str:
        """åˆ†æç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆ"""
        return f"""ã“ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ†æã—ã¦ã€ä»¥ä¸‹ã®æƒ…å ±ã‚’æŠ½å‡ºã—ã¦ãã ã•ã„ï¼š

1. ç™»å ´äººç‰©ã¨ãã®å½¹å‰²
2. è­°è«–ã•ã‚Œã¦ã„ã‚‹ãƒˆãƒ”ãƒƒã‚¯
3. æ¥­å‹™ãƒ•ãƒ­ãƒ¼ã‚„ãƒ—ãƒ­ã‚»ã‚¹
4. é‡è¦ãªæ´å¯Ÿ

ãƒ†ã‚­ã‚¹ãƒˆå†…å®¹ï¼š
{content}

åˆ†æçµæœã‚’JSONå½¢å¼ã§è¿”ã—ã¦ãã ã•ã„ã€‚"""
    
    def _get_default_analysis(self) -> Dict[str, Any]:
        """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®åˆ†æçµæœ"""
        return {
            "summary": "ãƒ“ã‚¸ãƒã‚¹ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®è¨˜éŒ²",
            "identified_persons": [],
            "topics": ["ä¸€èˆ¬çš„ãªæ¥­å‹™é€£çµ¡"],
            "workflows": [],
            "key_insights": ["è©³ç´°ãªåˆ†æã«ã¯ã‚ˆã‚Šå¤šãã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãŒå¿…è¦"],
            "confidence_scores": {
                "persons": 0.5,
                "workflows": 0.5,
                "topics": 0.5
            }
        }
    
    def interactive_improvement(self, analysis: Dict[str, Any]) -> Dict[str, Any]:
        """å¯¾è©±çš„ã«åˆ†æã‚’æ”¹å–„"""
        print("\n" + "=" * 60)
        print("ğŸ“ åˆ†æçµæœã®ç¢ºèª")
        print("=" * 60)
        
        self._display_analysis(analysis)
        
        while True:
            print("\nä¿®æ­£ãŒå¿…è¦ãªå ´åˆã¯å†…å®¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
            print("ï¼ˆä¾‹: ã€Œå±±ç”°ã•ã‚“ã¯å–¶æ¥­éƒ¨ã§ã¯ãªãé–‹ç™ºéƒ¨ã§ã™ã€ï¼‰")
            print("å•é¡Œãªã‘ã‚Œã°ã€ŒOKã€ã¨å…¥åŠ›ã—ã¦ãã ã•ã„")
            
            feedback = input("\n> ").strip()
            
            if feedback.upper() in ['OK', 'ã¯ã„', 'YES']:
                break
                
            # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’åæ˜ ï¼ˆå®Ÿéš›ã«ã¯Claude CodeãŒå†åˆ†æï¼‰
            print(f"\nğŸ’­ ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã€Œ{feedback}ã€ã‚’åæ˜ ã—ã¦ã„ã¾ã™...")
            # ã“ã“ã§åˆ†æã‚’æ›´æ–°
            
        return analysis
    
    def _display_analysis(self, analysis: Dict[str, Any]):
        """åˆ†æçµæœã‚’è¦‹ã‚„ã™ãè¡¨ç¤º"""
        print(f"\nğŸ“‹ è¦ç´„: {analysis['summary']}")
        
        if analysis['identified_persons']:
            print("\nğŸ‘¥ è­˜åˆ¥ã•ã‚ŒãŸäººç‰©:")
            for person in analysis['identified_persons']:
                print(f"  â€¢ {person['name']} - {person['role']} ({person['department']})")
                if person['activities']:
                    print(f"    æ´»å‹•: {', '.join(person['activities'][:3])}")
        
        if analysis['workflows']:
            print("\nğŸ”„ æ¥­å‹™ãƒ•ãƒ­ãƒ¼:")
            for wf in analysis['workflows']:
                print(f"  â€¢ {wf['name']}")
                print(f"    {' â†’ '.join(wf['steps'][:5])}")
        
        if analysis['key_insights']:
            print("\nğŸ’¡ é‡è¦ãªç™ºè¦‹:")
            for insight in analysis['key_insights']:
                print(f"  â€¢ {insight}")


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    if len(sys.argv) > 1:
        file_path = Path(sys.argv[1])
    else:
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ã‚µãƒ³ãƒ—ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆ†æ
        file_path = Path("data/raw/logs/[LINE]ï¼»SKã‚³ãƒ¼ãƒ æ§˜ï¼½.txt")
    
    if not file_path.exists():
        print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {file_path}")
        return
    
    print("ğŸš€ Claude Codeçµ±åˆå‹åˆ†æã‚·ã‚¹ãƒ†ãƒ ")
    print("=" * 60)
    
    analyzer = ClaudeCodeAnalyzer()
    
    # Claude Codeã¨é€£æºã—ã¦åˆ†æ
    analysis = analyzer.analyze_with_claude(file_path)
    
    # å¯¾è©±çš„æ”¹å–„
    final_analysis = analyzer.interactive_improvement(analysis)
    
    # çµæœã‚’ä¿å­˜
    output_dir = Path("output/claude_analysis")
    output_dir.mkdir(parents=True, exist_ok=True)
    
    output_file = output_dir / f"{file_path.stem}_analysis.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(final_analysis, f, ensure_ascii=False, indent=2)
    
    print(f"\nâœ… åˆ†æçµæœã‚’ä¿å­˜ã—ã¾ã—ãŸ: {output_file}")


if __name__ == "__main__":
    main()