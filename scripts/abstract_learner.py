#!/usr/bin/env python3
"""
æŠ½è±¡åŒ–å­¦ç¿’ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
å…·ä½“çš„ãªä¿®æ­£ã‹ã‚‰ä¸€èˆ¬çš„ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æŠ½å‡ºã—ã€å¿œç”¨å¯èƒ½ãªçŸ¥è­˜ã¨ã—ã¦è“„ç©
"""
import json
from pathlib import Path
from typing import Dict, List, Any, Optional, Set
from datetime import datetime
from collections import defaultdict
import re
import logging

logger = logging.getLogger(__name__)


class PatternExtractor:
    """ä¿®æ­£å±¥æ­´ã‹ã‚‰ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æŠ½å‡ºã™ã‚‹ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.patterns = {
            "naming_patterns": [],
            "role_patterns": [],
            "org_patterns": [],
            "context_patterns": []
        }
    
    def extract_naming_patterns(self, corrections: List[Dict]) -> List[Dict]:
        """åå‰ã«é–¢ã™ã‚‹ä¿®æ­£ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æŠ½å‡º"""
        patterns = []
        
        for correction in corrections:
            if correction.get('type') == 'entity':
                original = correction.get('original', {})
                corrected = correction.get('corrected', {})
                
                orig_name = original.get('name', '')
                corr_name = corrected.get('name', '')
                
                # ãƒ‘ã‚¿ãƒ¼ãƒ³1: åå‰ã®çœç•¥å½¢ â†’ ãƒ•ãƒ«ãƒãƒ¼ãƒ 
                if len(orig_name) < len(corr_name) and orig_name in corr_name:
                    patterns.append({
                        'type': 'abbreviation_to_fullname',
                        'example': f"{orig_name} â†’ {corr_name}",
                        'rule': 'çŸ­ã„åå‰ã¯å§“åã®ä¸€éƒ¨ã®å¯èƒ½æ€§ãŒé«˜ã„',
                        'confidence_boost': -0.2  # çœç•¥å½¢ã®å ´åˆã¯ä¿¡é ¼åº¦ã‚’ä¸‹ã’ã‚‹
                    })
                
                # ãƒ‘ã‚¿ãƒ¼ãƒ³2: æ¼¢å­—ã®èª­ã¿é–“é•ã„
                if self._is_similar_reading(orig_name, corr_name):
                    patterns.append({
                        'type': 'kanji_misreading',
                        'example': f"{orig_name} â†’ {corr_name}",
                        'rule': 'ä¼¼ãŸèª­ã¿ã®æ¼¢å­—ã«æ³¨æ„',
                        'check_similar_kanji': True
                    })
        
        return patterns
    
    def extract_role_patterns(self, corrections: List[Dict]) -> List[Dict]:
        """å½¹è·ã«é–¢ã™ã‚‹ä¿®æ­£ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æŠ½å‡º"""
        patterns = []
        role_upgrades = defaultdict(list)
        
        for correction in corrections:
            if correction.get('type') == 'entity':
                orig_role = correction.get('original', {}).get('role', '')
                corr_role = correction.get('corrected', {}).get('role', '')
                
                if orig_role and corr_role and orig_role != corr_role:
                    # å½¹è·ã®æ ¼ä¸Šã’ãƒ‘ã‚¿ãƒ¼ãƒ³
                    if self._is_role_upgrade(orig_role, corr_role):
                        role_upgrades['upgrade'].append({
                            'from': orig_role,
                            'to': corr_role,
                            'context': correction.get('context', '')
                        })
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³åŒ–
        if len(role_upgrades['upgrade']) >= 2:
            patterns.append({
                'type': 'role_underestimation',
                'rule': 'å°è¦æ¨¡çµ„ç¹”ã§ã¯ä¸Šä½å½¹è·è€…ãŒç›´æ¥å¯¾å¿œã™ã‚‹ã“ã¨ãŒå¤šã„',
                'examples': role_upgrades['upgrade'],
                'action': 'consider_higher_roles'
            })
        
        return patterns
    
    def extract_org_patterns(self, corrections: List[Dict]) -> List[Dict]:
        """çµ„ç¹”ãƒ»æ‰€å±ã«é–¢ã™ã‚‹ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æŠ½å‡º"""
        patterns = []
        org_mistakes = []
        
        for correction in corrections:
            if correction.get('type') == 'entity':
                orig_dept = correction.get('original', {}).get('department', '')
                corr_dept = correction.get('corrected', {}).get('department', '')
                
                # ãƒ•ãƒªãƒ¼ãƒ©ãƒ³ã‚¹èª¤èªãƒ‘ã‚¿ãƒ¼ãƒ³
                if 'ãƒ•ãƒªãƒ¼ãƒ©ãƒ³ã‚¹' in corr_dept and 'ã‚°ãƒ«ãƒ¼ãƒ—' in orig_dept:
                    org_mistakes.append({
                        'pattern': 'freelance_misidentified_as_employee',
                        'indicator': 'ä»²ä»‹çš„ãªå‹•ãã‚’ã—ã¦ã„ã‚‹äººç‰©'
                    })
        
        if org_mistakes:
            patterns.append({
                'type': 'organization_affiliation',
                'rule': 'ä»²ä»‹è€…ã‚„ã‚³ãƒ¼ãƒ‡ã‚£ãƒãƒ¼ã‚¿ãƒ¼ã¯ãƒ•ãƒªãƒ¼ãƒ©ãƒ³ã‚¹ã®å¯èƒ½æ€§ã‚’è€ƒæ…®',
                'indicators': ['è¤‡æ•°çµ„ç¹”é–“ã®èª¿æ•´', 'å¤–éƒ¨ã‹ã‚‰ã®ç™ºæ³¨', 'ç‹¬ç«‹ã—ãŸç«‹å ´ã§ã®äº¤æ¸‰']
            })
        
        return patterns
    
    def _is_similar_reading(self, name1: str, name2: str) -> bool:
        """ä¼¼ãŸèª­ã¿ã®å¯èƒ½æ€§ãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯"""
        # ç°¡æ˜“å®Ÿè£…ï¼šæ–‡å­—æ•°ãŒåŒã˜ã§ä¸€éƒ¨ãŒå…±é€š
        return len(name1) == len(name2) and any(c in name2 for c in name1)
    
    def _is_role_upgrade(self, orig: str, corrected: str) -> bool:
        """å½¹è·ãŒä¸Šä½ã«ä¿®æ­£ã•ã‚ŒãŸã‹ãƒã‚§ãƒƒã‚¯"""
        lower_roles = ['æ‹…å½“', 'ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼', 'ãƒªãƒ¼ãƒ€ãƒ¼', 'ä¸»ä»»']
        higher_roles = ['ç¤¾é•·', 'ä»£è¡¨', 'å–ç· å½¹', 'CEO', 'ã‚ªãƒ¼ãƒŠãƒ¼']
        
        return any(l in orig for l in lower_roles) and any(h in corrected for h in higher_roles)


class AbstractLearner:
    """æŠ½è±¡çš„ãªå­¦ç¿’ã‚’è¡Œã†ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, knowledge_base_path: str = "data/feedback/abstract_knowledge.json"):
        self.knowledge_path = Path(knowledge_base_path)
        self.knowledge_path.parent.mkdir(parents=True, exist_ok=True)
        self.pattern_extractor = PatternExtractor()
        self.load_abstract_knowledge()
    
    def load_abstract_knowledge(self):
        """æŠ½è±¡çš„ãªçŸ¥è­˜ã‚’èª­ã¿è¾¼ã‚€"""
        if self.knowledge_path.exists():
            with open(self.knowledge_path, 'r', encoding='utf-8') as f:
                self.abstract_knowledge = json.load(f)
        else:
            self.abstract_knowledge = {
                "learned_patterns": [],
                "inference_rules": [],
                "context_rules": [],
                "meta_statistics": {
                    "total_corrections": 0,
                    "pattern_success_rate": {}
                }
            }
    
    def save_abstract_knowledge(self):
        """æŠ½è±¡çš„ãªçŸ¥è­˜ã‚’ä¿å­˜"""
        with open(self.knowledge_path, 'w', encoding='utf-8') as f:
            json.dump(self.abstract_knowledge, f, ensure_ascii=False, indent=2)
    
    def learn_from_corrections(self, corrections: List[Dict]):
        """ä¿®æ­£å±¥æ­´ã‹ã‚‰æŠ½è±¡çš„ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å­¦ç¿’"""
        # å„ç¨®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æŠ½å‡º
        naming_patterns = self.pattern_extractor.extract_naming_patterns(corrections)
        role_patterns = self.pattern_extractor.extract_role_patterns(corrections)
        org_patterns = self.pattern_extractor.extract_org_patterns(corrections)
        
        # æ–°ã—ã„ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã«è¿½åŠ 
        all_patterns = naming_patterns + role_patterns + org_patterns
        
        for pattern in all_patterns:
            if not self._is_duplicate_pattern(pattern):
                pattern['learned_at'] = datetime.now().isoformat()
                pattern['usage_count'] = 0
                pattern['success_rate'] = 1.0
                self.abstract_knowledge['learned_patterns'].append(pattern)
        
        # æ¨è«–ãƒ«ãƒ¼ãƒ«ã‚’ç”Ÿæˆ
        self._generate_inference_rules(all_patterns)
        
        # çµ±è¨ˆã‚’æ›´æ–°
        self.abstract_knowledge['meta_statistics']['total_corrections'] = len(corrections)
        
        self.save_abstract_knowledge()
        logger.info(f"Learned {len(all_patterns)} new patterns from corrections")
    
    def _is_duplicate_pattern(self, pattern: Dict) -> bool:
        """æ—¢å­˜ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã¨é‡è¤‡ã—ã¦ã„ãªã„ã‹ãƒã‚§ãƒƒã‚¯"""
        for existing in self.abstract_knowledge['learned_patterns']:
            if (existing.get('type') == pattern.get('type') and 
                existing.get('rule') == pattern.get('rule')):
                return True
        return False
    
    def _generate_inference_rules(self, patterns: List[Dict]):
        """ãƒ‘ã‚¿ãƒ¼ãƒ³ã‹ã‚‰æ¨è«–ãƒ«ãƒ¼ãƒ«ã‚’ç”Ÿæˆ"""
        rules = []
        
        # åå‰ã«é–¢ã™ã‚‹ãƒ«ãƒ¼ãƒ«
        name_patterns = [p for p in patterns if 'naming' in p.get('type', '')]
        if len(name_patterns) >= 2:
            rules.append({
                'id': 'name_fullform_preference',
                'condition': 'ãƒ“ã‚¸ãƒã‚¹ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã§ã®äººå',
                'action': 'ãƒ•ãƒ«ãƒãƒ¼ãƒ ã‚’å„ªå…ˆçš„ã«æ¨å®š',
                'confidence_adjustment': 0.8
            })
        
        # å½¹è·ã«é–¢ã™ã‚‹ãƒ«ãƒ¼ãƒ«
        role_patterns = [p for p in patterns if 'role' in p.get('type', '')]
        if role_patterns:
            rules.append({
                'id': 'small_org_executive_involvement',
                'condition': 'å°è¦æ¨¡çµ„ç¹”ã§ã®ç›´æ¥çš„ãªã‚„ã‚Šå–ã‚Š',
                'action': 'ä¸Šä½å½¹è·è€…ã®å¯èƒ½æ€§ã‚’è€ƒæ…®',
                'role_candidates': ['ä»£è¡¨', 'ç¤¾é•·', 'ã‚ªãƒ¼ãƒŠãƒ¼']
            })
        
        # æ–°ã—ã„ãƒ«ãƒ¼ãƒ«ã‚’è¿½åŠ 
        for rule in rules:
            if not any(r.get('id') == rule.get('id') for r in self.abstract_knowledge['inference_rules']):
                self.abstract_knowledge['inference_rules'].append(rule)
    
    def apply_abstract_knowledge(self, analysis: Dict[str, Any]) -> Dict[str, Any]:
        """æŠ½è±¡çš„ãªçŸ¥è­˜ã‚’æ–°ã—ã„åˆ†æã«é©ç”¨"""
        enhanced_analysis = analysis.copy()
        applied_patterns = []
        
        # äººç‰©æƒ…å ±ã«å¯¾ã—ã¦ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’é©ç”¨
        if 'identified_persons' in enhanced_analysis:
            for person in enhanced_analysis['identified_persons']:
                # åå‰ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒã‚§ãƒƒã‚¯
                name_adjustments = self._apply_naming_patterns(person)
                if name_adjustments:
                    person.update(name_adjustments)
                    applied_patterns.append(f"åå‰ãƒ‘ã‚¿ãƒ¼ãƒ³é©ç”¨: {person['name']}")
                
                # å½¹è·ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒã‚§ãƒƒã‚¯
                role_adjustments = self._apply_role_patterns(person, enhanced_analysis)
                if role_adjustments:
                    person.update(role_adjustments)
                    applied_patterns.append(f"å½¹è·ãƒ‘ã‚¿ãƒ¼ãƒ³é©ç”¨: {person['role']}")
                
                # çµ„ç¹”ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒã‚§ãƒƒã‚¯
                org_adjustments = self._apply_org_patterns(person, enhanced_analysis)
                if org_adjustments:
                    person.update(org_adjustments)
                    applied_patterns.append(f"çµ„ç¹”ãƒ‘ã‚¿ãƒ¼ãƒ³é©ç”¨: {person['department']}")
        
        # é©ç”¨ã—ãŸãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è¨˜éŒ²
        if applied_patterns:
            enhanced_analysis['abstract_patterns_applied'] = applied_patterns
            logger.info(f"Applied {len(applied_patterns)} abstract patterns")
        
        return enhanced_analysis
    
    def _apply_naming_patterns(self, person: Dict) -> Optional[Dict]:
        """åå‰ã«é–¢ã™ã‚‹ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’é©ç”¨"""
        adjustments = {}
        name = person.get('name', '')
        
        # çŸ­ã„åå‰ã®å ´åˆã€ãƒ•ãƒ«ãƒãƒ¼ãƒ ã®å¯èƒ½æ€§ã‚’ç¤ºå”†
        if len(name) <= 3 and not ' ' in name:
            for pattern in self.abstract_knowledge['learned_patterns']:
                if pattern.get('type') == 'abbreviation_to_fullname':
                    adjustments['name_confidence'] = 0.7
                    adjustments['name_note'] = 'ãƒ•ãƒ«ãƒãƒ¼ãƒ ã§ã¯ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™'
                    break
        
        return adjustments
    
    def _apply_role_patterns(self, person: Dict, full_analysis: Dict) -> Optional[Dict]:
        """å½¹è·ã«é–¢ã™ã‚‹ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’é©ç”¨"""
        adjustments = {}
        current_role = person.get('role', '')
        
        # å°è¦æ¨¡çµ„ç¹”ã§ã®å½¹è·æ¨å®š
        for rule in self.abstract_knowledge['inference_rules']:
            if rule.get('id') == 'small_org_executive_involvement':
                # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰å°è¦æ¨¡çµ„ç¹”ã‹ã©ã†ã‹ã‚’åˆ¤æ–­
                if self._is_small_organization_context(full_analysis):
                    if any(keyword in current_role for keyword in ['æ‹…å½“', 'ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼']):
                        adjustments['alternative_roles'] = rule.get('role_candidates', [])
                        adjustments['role_confidence'] = 0.6
        
        return adjustments
    
    def _apply_org_patterns(self, person: Dict, full_analysis: Dict) -> Optional[Dict]:
        """çµ„ç¹”ã«é–¢ã™ã‚‹ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’é©ç”¨"""
        adjustments = {}
        activities = person.get('activities', [])
        
        # ãƒ•ãƒªãƒ¼ãƒ©ãƒ³ã‚¹ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ãƒã‚§ãƒƒã‚¯
        freelance_indicators = ['ä»²ä»‹', 'è¤‡æ•°çµ„ç¹”', 'å¤–éƒ¨', 'ç‹¬ç«‹']
        if any(any(ind in act for ind in freelance_indicators) for act in activities):
            for pattern in self.abstract_knowledge['learned_patterns']:
                if pattern.get('type') == 'organization_affiliation':
                    adjustments['org_note'] = 'ãƒ•ãƒªãƒ¼ãƒ©ãƒ³ã‚¹ã¾ãŸã¯å¤–éƒ¨å”åŠ›è€…ã®å¯èƒ½æ€§'
                    adjustments['org_confidence'] = 0.7
                    break
        
        return adjustments
    
    def _is_small_organization_context(self, analysis: Dict) -> bool:
        """å°è¦æ¨¡çµ„ç¹”ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‹ã©ã†ã‹ã‚’åˆ¤æ–­"""
        # ç°¡æ˜“çš„ãªåˆ¤æ–­: è­˜åˆ¥ã•ã‚ŒãŸäººç‰©ãŒ5äººä»¥ä¸‹
        persons = analysis.get('identified_persons', [])
        return len(persons) <= 5
    
    def generate_learning_report(self) -> str:
        """æŠ½è±¡çš„å­¦ç¿’ã®ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        report = ["=== æŠ½è±¡çš„å­¦ç¿’ãƒ¬ãƒãƒ¼ãƒˆ ===\n"]
        
        # å­¦ç¿’ã—ãŸãƒ‘ã‚¿ãƒ¼ãƒ³
        patterns = self.abstract_knowledge['learned_patterns']
        if patterns:
            report.append(f"ğŸ§  å­¦ç¿’ã—ãŸãƒ‘ã‚¿ãƒ¼ãƒ³æ•°: {len(patterns)}")
            
            # ã‚¿ã‚¤ãƒ—åˆ¥ã«åˆ†é¡
            by_type = defaultdict(list)
            for p in patterns:
                by_type[p.get('type', 'unknown')].append(p)
            
            for ptype, items in by_type.items():
                report.append(f"\nğŸ“Œ {ptype}:")
                for item in items[:3]:  # æœ€åˆã®3ã¤
                    report.append(f"  - {item.get('rule', 'No rule')}")
                    if 'example' in item:
                        report.append(f"    ä¾‹: {item['example']}")
        
        # æ¨è«–ãƒ«ãƒ¼ãƒ«
        rules = self.abstract_knowledge['inference_rules']
        if rules:
            report.append(f"\nğŸ”§ ç”Ÿæˆã•ã‚ŒãŸæ¨è«–ãƒ«ãƒ¼ãƒ«: {len(rules)}")
            for rule in rules:
                report.append(f"  - {rule.get('condition')} â†’ {rule.get('action')}")
        
        # çµ±è¨ˆæƒ…å ±
        stats = self.abstract_knowledge['meta_statistics']
        report.append(f"\nğŸ“Š çµ±è¨ˆ:")
        report.append(f"  - ç·ä¿®æ­£æ•°: {stats.get('total_corrections', 0)}")
        
        return "\n".join(report)


class PreventiveLearner:
    """äºˆé˜²çš„ãªå­¦ç¿’ã‚’è¡Œã†ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, abstract_learner: AbstractLearner):
        self.abstract_learner = abstract_learner
        self.warning_threshold = 0.7
    
    def analyze_potential_errors(self, analysis: Dict[str, Any]) -> List[Dict]:
        """æ½œåœ¨çš„ãªã‚¨ãƒ©ãƒ¼ã‚’åˆ†æã—ã¦è­¦å‘Šã‚’ç”Ÿæˆ"""
        warnings = []
        
        # äººç‰©æƒ…å ±ã®ãƒã‚§ãƒƒã‚¯
        for person in analysis.get('identified_persons', []):
            # åå‰ã®è­¦å‘Š
            if person.get('name_confidence', 1.0) < self.warning_threshold:
                warnings.append({
                    'type': 'name_uncertainty',
                    'target': person['name'],
                    'message': f"{person['name']}ã¯ãƒ•ãƒ«ãƒãƒ¼ãƒ ã§ã¯ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™",
                    'suggestion': 'æ­£å¼ãªåå‰ã‚’ç¢ºèªã—ã¦ãã ã•ã„'
                })
            
            # å½¹è·ã®è­¦å‘Š
            if person.get('role_confidence', 1.0) < self.warning_threshold:
                alt_roles = person.get('alternative_roles', [])
                if alt_roles:
                    warnings.append({
                        'type': 'role_uncertainty',
                        'target': person['name'],
                        'current': person.get('role'),
                        'alternatives': alt_roles,
                        'message': f"{person['name']}ã®å½¹è·ã¯{alt_roles}ã®å¯èƒ½æ€§ã‚‚ã‚ã‚Šã¾ã™"
                    })
            
            # çµ„ç¹”ã®è­¦å‘Š
            if person.get('org_confidence', 1.0) < self.warning_threshold:
                warnings.append({
                    'type': 'org_uncertainty',
                    'target': person['name'],
                    'message': person.get('org_note', 'æ‰€å±çµ„ç¹”ã«ä¸ç¢ºå®Ÿæ€§ãŒã‚ã‚Šã¾ã™')
                })
        
        return warnings
    
    def suggest_verifications(self, warnings: List[Dict]) -> List[str]:
        """è­¦å‘Šã«åŸºã¥ã„ã¦ç¢ºèªã™ã¹ãé …ç›®ã‚’ææ¡ˆ"""
        suggestions = []
        
        # è­¦å‘Šã‚¿ã‚¤ãƒ—åˆ¥ã«ç¢ºèªé …ç›®ã‚’ç”Ÿæˆ
        name_warnings = [w for w in warnings if w['type'] == 'name_uncertainty']
        if name_warnings:
            suggestions.append("ğŸ“ ä»¥ä¸‹ã®äººç‰©ã®æ­£å¼åç§°ã‚’ç¢ºèªã—ã¦ãã ã•ã„:")
            for w in name_warnings:
                suggestions.append(f"  - {w['target']}")
        
        role_warnings = [w for w in warnings if w['type'] == 'role_uncertainty']
        if role_warnings:
            suggestions.append("\nğŸ‘¤ ä»¥ä¸‹ã®äººç‰©ã®æ­£ç¢ºãªå½¹è·ã‚’ç¢ºèªã—ã¦ãã ã•ã„:")
            for w in role_warnings:
                alts = ', '.join(w['alternatives'])
                suggestions.append(f"  - {w['target']}: ç¾åœ¨ã€Œ{w['current']}ã€â†’ å¯èƒ½æ€§ã€Œ{alts}ã€")
        
        org_warnings = [w for w in warnings if w['type'] == 'org_uncertainty']
        if org_warnings:
            suggestions.append("\nğŸ¢ ä»¥ä¸‹ã®äººç‰©ã®æ‰€å±ã‚’å†ç¢ºèªã—ã¦ãã ã•ã„:")
            for w in org_warnings:
                suggestions.append(f"  - {w['target']}: {w['message']}")
        
        return suggestions


if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    learner = AbstractLearner()
    
    # ã‚µãƒ³ãƒ—ãƒ«ä¿®æ­£ãƒ‡ãƒ¼ã‚¿
    sample_corrections = [
        {
            "timestamp": "2025-01-13T10:00:00",
            "type": "entity",
            "original": {"name": "ã¾ã‚†", "role": "æ‹…å½“"},
            "corrected": {"name": "å››ãƒå®®ã¾ã‚†", "role": "è£½ä½œæ‹…å½“"},
            "context": "ãƒ•ãƒ«ãƒãƒ¼ãƒ ã¸ã®ä¿®æ­£"
        },
        {
            "timestamp": "2025-01-13T10:05:00",
            "type": "entity",
            "original": {"name": "ã‚Šã‚‡ã†ãŸ", "role": "ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼"},
            "corrected": {"name": "è…é‡éš†å¤ª", "role": "ä»£è¡¨å–ç· å½¹ç¤¾é•·"},
            "context": "å½¹è·ã®ä¿®æ­£"
        }
    ]
    
    # ãƒ‘ã‚¿ãƒ¼ãƒ³å­¦ç¿’
    learner.learn_from_corrections(sample_corrections)
    
    # ãƒ¬ãƒãƒ¼ãƒˆè¡¨ç¤º
    print(learner.generate_learning_report())